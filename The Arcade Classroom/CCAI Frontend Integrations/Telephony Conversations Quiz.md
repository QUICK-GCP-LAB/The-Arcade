### **Telephony Integration and Advanced Speech Features Quiz**  

**ðŸ“‹ Passing Score: 80%**  

---

#### **Question 1:** Which of the following are sent through telephony integrationâ€™s gRPC to the CCAI APIs? *(Choose three)*  

ðŸŸ¢ **Options:**  
1. âšª The callerâ€™s geolocation  
2. ðŸŸ¢ **Session parameters**  
3. âšª End of speech detection 
4. âšª Start of speech detection
5. ðŸŸ¢ **The callerâ€™s audio stream**
6. ðŸŸ¢ **Programmatic events that change the conversation state**

---  

#### **Question 2:** Which of the following are returned from the CCAI APIs through the telephony integrationâ€™s gRPC? *(Choose three)*  

ðŸŸ¢ **Options:**  
1. âšª The callerâ€™s geolocation  
2. ðŸŸ¢ **Programmatic events that change the conversation state**  
3. ðŸŸ¢ **Session parameters**  
4. ðŸŸ¢ **Start of speech detection**
5. âšª The Callerâ€™s IP Address  
6. âšª The callerâ€™s audio stream

---  

#### **Question 3:** Which of the following features could help reliably authenticate users to your virtual agent? *(Choose three)*  

ðŸŸ¢ **Options:**  
1. ðŸŸ¢ **I can cross-reference Caller ID with a DTMF-collected pin code**  
2. âšª Speaker ID tells me which one of my many enrolled users is speaking
3. ðŸŸ¢ **I can lookup known users from Caller ID then use Speaker ID to tell me which one is speaking**  
4. ðŸŸ¢ **I can use a regexp entity and collect an alpha/numeric ID with required form-filling**  
5. âšª I can use a regexp entity and collect an alpha/numeric ID by annotating the entity in intent training phrases.  

---  

#### **Question 4:** Google support asks you to share an audio recording of a problem behavior youâ€™ve reported with your telephony experience. Which of the following considerations should you take? *(Choose two)*  

ðŸŸ¢ **Options:**  
1. âšª Encode as MP3 files so they can be shared with support more easily  
2. ðŸŸ¢ **Check that the caller and agent audio are in separate files, or separate channels of a stereo audio.**  
3. ðŸŸ¢ **Record calls from your CCAI contact center solution.**  
4. âšª Record your call from an app on your phone to get the original audio source.  
5. âšª Test in the Dialogflow console and record your screen and mic.  

---  

#### **Question 5:** When you test your virtual agent through your telephony integration, you experience long periods of silence before hearing a response to your inputs. How might you fix this? *(Choose four)*  

ðŸŸ¢ **Options:**  
1. âšª Enable advanced timeout-based endpointing and decrease the sensitivity slider.  
2. ðŸŸ¢ **Enable advanced timeout-based endpointing and increase the sensitivity slider.**  
3. ðŸŸ¢ **Specify a different speech model.**  
4. ðŸŸ¢ **Check the performance of my fulfillmentsâ€™ webhooks.**  
5. âšª My integration offers an option to specify the maximum number of seconds to wait after a user speaks. 
6. ðŸŸ¢ **Contact my integration owner for troubleshooting any networking or other processing issues.**  

---  

#### **Question 6:** Built-in Dialogflow features like barge-in, speech adaptation, and partial responses ensure consistent experiences regardless of your integration method.  

ðŸŸ¢ **Options:**  
1. ðŸŸ¢ **False**
2. âšª True  

---  

#### **Question 7:** You need at least one conversation profile per: *(Choose three)*  

ðŸŸ¢ **Options:**  
1. ðŸŸ¢ **Dialogflow agent**  
2. âšª Release version  
3. ðŸŸ¢ **Language**  
4. ðŸŸ¢ **Unique Agent Assist feature combination**  
5. âšª Human Agent  
6. âšª Session  

---  

#### **Question 8:** Your virtual agent has trouble understanding users. When you check Dialogflow conversation history, the transcripts do not match what the user said. How might you fix this?  

ðŸŸ¢ **Options:**  
1. ðŸŸ¢ **Configure a different Google speech model better suited for my use-case.**  
2. ðŸŸ¢ **Ensure that I collect alpha/numeric sequences (like 12345678 or ABCD1234) through form-filling.**
3. ðŸŸ¢ **Enable call companions to offer users an alternative input method.**
4. âšª Thereâ€™s nothing I can do without implementing my own speech recognition.  
5. ðŸŸ¢ **Check that auto speech adaptation is enabled, then make sure the agentâ€™s training phrases and entities contain the phrases the users are actually saying.**  
6. âšª Be patient. Google models will eventually adapt to my usersâ€™ speech and my use-case.  
7. ðŸŸ¢ **Specify manual speech adaptations for the phrases I want to transcribe correctly.**  

---  

#### **Question 9:** Which of the following advanced speech settings is most impactful to the performance of your solution?  

ðŸŸ¢ **Options:**  
1. âšª End of speech sensitivity
2. âšª Advanced timeout-based endpointing  
3. âšª Barge-in  
4. ðŸŸ¢ **Speech model**  

---

### ðŸŽ‰ **Congratulations!**  
##### *Youâ€™ve successfully completed the Telephony Integration and Advanced Speech Features Quiz!*  

#### *Excellent workâ€”mastering these topics ensures smooth telephony integrations with Dialogflow CX!*  

**Connect with the community on our** [Telegram Channel](https://t.me/quickgcplab) **and share insights in the** [Discussion Group](https://t.me/quickgcplabchats).  

# [QUICK GCP LAB](https://www.youtube.com/@quickgcplab)